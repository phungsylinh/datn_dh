import re
from sentimentanalysis.replace_file import replaces
from pyvi import ViTokenizer
from sentimentanalysis.vob import pos_vob , neg_vob , not_vob

def process_data(text):
	text = text.lower()
	text = re.sub(r"\b[a-zA-Z]\b", "", str(text))
	for i, j in replaces.items():
		text = text.replace(i,j)
	text = re.sub(r'(.)\1+', r'\1', text) #Chuy·ªÉn nhi·ªÅu h∆°n 1 ch·ªØu v·ªÅ 1 ch·ªØ
	text = re.sub(r"\s+", " ", str(text)) #Chuy·ªÉn nhi·ªÅu kho·∫£ng tr·∫Øng v·ªÅ 1 kho·∫£ng tr·∫Øng
	text = ViTokenizer.tokenize(text)
	texts = text.split()
	texts = [t.replace('_', ' ') for t in texts]
	len_text = len(texts)
	for i in range(len_text):
		cp_text = texts[i]
		if cp_text in not_vob: # X·ª≠ l√Ω v·∫•n ƒë·ªÅ ph·ªß ƒë·ªãnh (VD: kh√¥ng x·∫•u--> notnag)
			numb_word = 2 if len_text - i - 1 >= 4 else len_text - i - 1            
			for j in range(numb_word):
				if texts[i + j + 1] in pos_vob:
					texts[i] = 'notpos'
					texts[i + j + 1] = ''

				if texts[i + j + 1] in neg_vob:
					texts[i] = 'notneg'
					texts[i + j + 1] = ''
	text = u' '.join(texts)
	# x√≥a k√Ω t·ª± th·ª´a
	text = re.sub(r"\d+", " ", str(text))
	text = re.sub(r"\,", " ", str(text))
	text = re.sub(r"\?", "", str(text))
	text = re.sub(r"\.", "", str(text))
	text = re.sub(r"\!", "", str(text))
	text = text.replace(u'"', u' ')
	text = text.replace(u'Ô∏è', u'')
	text = text.replace('üèª','')
	return text